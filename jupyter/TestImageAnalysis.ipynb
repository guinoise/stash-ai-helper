{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8034b9c5-872a-401d-928a-3c8111c29fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import pathlib\n",
    "main_path= pathlib.Path('..')\n",
    "print (main_path.resolve())\n",
    "sys.path.insert(0, str(main_path.resolve()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c62b53-d241-4905-bca2-3746fb78ccd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger= logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee634a6-b08a-410b-936e-6f18d9dffc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.core.display as display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b0fdd3-9601-4318-8933-f7ff79961eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import stash_ai.config as stash_ai_config\n",
    "from stash_ai.config import config\n",
    "stash_ai_config.config_file= main_path.joinpath('config.json')\n",
    "print(stash_ai_config.config_file.resolve())\n",
    "stash_ai_config.load_config()\n",
    "config.base_dir\n",
    "from stash_ai.db import get_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e07c8ed-e6f3-49d5-a864-65e451f0e70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.custom_logging import get_logger\n",
    "logger= get_logger(\"stash_ai.stash_scenes\", True)\n",
    "\n",
    "import gradio as gr\n",
    "if gr.NO_RELOAD:\n",
    "    from deepface import DeepFace\n",
    "from stash_ai.config import config\n",
    "from stash_ai.db import get_session\n",
    "from stash_ai.model import Performer, Scene, Img, ImgFile, ImageAnalysis, DeepfaceFace, FaceStatus\n",
    "from utils.performer import get_performer_stash_image, load_performer, get_unknown_performer_image\n",
    "from utils.scene import load_scene, create_or_update_scene_from_stash, extract_scene_images, decord_scene\n",
    "from utils.image import image_analysis, get_annotated_image_analysis_path, get_face_image_path, get_face_phash, hashes_are_similar, group_faces, load_image_analysis_from_imgFiles\n",
    "from datetime import timedelta\n",
    "import random\n",
    "from PIL import Image\n",
    "from tqdm import tqdm \n",
    "from typing import List, Dict\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03b310d-94fc-4b56-b0f1-9c115cbc5b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stash_ai.stash_scenes import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f641ca0-55ad-411d-877f-359828de3ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.performer import get_performer_stash_image, load_performer, get_unknown_performer_image\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3113a2-4fe7-4159-b474-62861e11791e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_id= 1392\n",
    "state_scene_stash= {}\n",
    "state_scene_stash= handler_load_scene(scene_id, state_scene_stash)\n",
    "html, performers_images, state_scene_stash, nb_images= update_scene_infos(state_scene_stash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1302a90-3356-4f0f-be0e-42deefd8c96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "display.HTML(html)\n",
    "#print (performers_images)\n",
    "#for im in performers_images:\n",
    "#    display.Image(im)\n",
    "#, performers_images, state_scene_stash, nb_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110f0a8d-859b-46e9-a51b-31455e5f194c",
   "metadata": {},
   "outputs": [],
   "source": [
    "display.JSON(state_scene_stash)\n",
    "#print (performers_images)\n",
    "#for im in performers_images:\n",
    "#    display.Image(im)\n",
    "#, performers_images, state_scene_stash, nb_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce87dab-507b-400d-b297-f214aa439786",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_deepface_ident_face_conf=0.9\n",
    "number_ident_hash_tolerance=15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dcf2ff-945d-4936-96a4-b6be97e1f056",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(f\"ident_faces detector {config.face_recognition_model} min_confidence face {number_deepface_ident_face_conf} hash tolerance {number_ident_hash_tolerance} model {config.face_identification_model}\")\n",
    "logger.debug(f\"ident_faces {state_scene_stash}\")\n",
    "dataset_dir= config.data_dir.joinpath('dataset/performers')\n",
    "logger.info(f\"Dataset dir: {dataset_dir.resolve()}\")\n",
    "if not dataset_dir.exists():\n",
    "    logger.critical(f\"Dataset directory does not exists {dataset_dir.resolve()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfe520a-b7fb-4d47-84e5-09aea385bb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with get_session() as session:\n",
    "    for group_name, faces_list in state_scene_stash.get('groups', {}).items():\n",
    "        logger.info(f\"Group {group_name}\")\n",
    "        frames_results= []\n",
    "        paths= []\n",
    "        for face_id in faces_list:\n",
    "            face: DeepfaceFace= session.get(DeepfaceFace, face_id)\n",
    "            df= DeepFace.find(get_face_image_path(face), db_path=dataset_dir.resolve(), detector_backend=config.face_recognition_model, model_name=config.face_identification_model, enforce_detection=False)\n",
    "            frames_results.append(df[0])\n",
    "        df= pd.concat(frames_results)\n",
    "        perf_ids= []\n",
    "        perf_names= []\n",
    "        for path in df.identity:\n",
    "            #relative_path= pathlib.Path(path).relative_to(config.data_dir)\n",
    "            match_face_id= int(pathlib.Path(path).stem.split(\"_\")[0])\n",
    "            match_face: DeepfaceFace= session.get(DeepfaceFace, match_face_id)\n",
    "            if match_face is None or match_face.performer is None:\n",
    "                perf_ids.append(None)\n",
    "                perf_names.append(None)\n",
    "            else:\n",
    "                perf_ids.append(match_face.performer.id)\n",
    "                perf_names.append(match_face.performer.name)\n",
    "        df['PerformerId'] = perf_ids\n",
    "        df['PerformerName'] = perf_names\n",
    "        df['score']= ((df.groupby('PerformerId')['PerformerId'].transform('size')/len(df))+1) * df.groupby('PerformerId')['threshold'].transform('max')\n",
    "        s= df.groupby('PerformerId').agg(\"max\").sort_values('score', ascending=False).head(3)\n",
    "        s.reset_index()\n",
    "        for index, row in s.iterrows():\n",
    "            print(f\"id: {index} {row['PerformerName']} {round(row['score'],3)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a1be99-2021-406e-b063-5365501d08b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff247a5-8ac1-48af-9a4b-7735b938b7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('PerformerId').agg(\"max\").sort_values('score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a8db32-605a-4112-8883-94bb418833aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "s= df[df['score'] > 0.65].groupby('PerformerId').agg(\"max\").sort_values('score', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91106c47-601b-4d62-bd70-5c0e5d211dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.reset_index()\n",
    "for performer_id, row in s.iterrows():\n",
    "    print(f\"{performer_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee42d48a-031a-4866-8d51-e40111c89d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "s= df.groupby('PerformerId').agg(\"max\").sort_values('score', ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb09b6c-0327-4249-81d5-dcc35371d4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.reset_index()\n",
    "for index, row in s.iterrows():\n",
    "    print(f\"id: {index} {row['PerformerName']} {round(row['score'],3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f63d0c-43f7-4b0f-8d1a-16cd5bbfa74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_ids= []\n",
    "perf_names= []\n",
    "with get_session() as session:\n",
    "    for path in df.identity:\n",
    "        #relative_path= pathlib.Path(path).relative_to(config.data_dir)\n",
    "        match_face_id= int(pathlib.Path(path).stem.split(\"_\")[0])\n",
    "        match_face: DeepfaceFace= session.get(DeepfaceFace, match_face_id)\n",
    "        if match_face is None or match_face.performer is None:\n",
    "            perf_ids.append(None)\n",
    "            perf_names.append(None)\n",
    "        else:\n",
    "            perf_ids.append(match_face.performer.id)\n",
    "            perf_names.append(match_face.performer.name)\n",
    "    df['PerformerId'] = perf_ids\n",
    "    df['PerformerName'] = perf_names\n",
    "    df['score']= ((df.groupby('PerformerId')['PerformerId'].transform('size')/len(df))+1) * df.groupby('PerformerId')['threshold'].transform('max')    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5a1dd8-e985-485c-88bb-41320168a252",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped= df.groupby(['PerformerId', 'PerformerName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57be0e2-993d-4326-a593-bbd3b895942f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['score']= ((df.groupby('PerformerId')['PerformerId'].transform('size')/len(df))+1) * df.groupby('PerformerId')['threshold'].transform('max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81c39f4-7e8b-4bbb-9026-30e309d4ce58",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.agg(count=pd.NamedAgg(column=\"hash\", aggfunc=\"count\"), threshold=pd.NamedAgg(column=\"threshold\", aggfunc=\"mean\")).sort_values([\"count\", \"threshold\"], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27164746-0d4a-441a-a4f3-9e69eda57b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from deepface import DeepFace\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pathlib\n",
    "from matplotlib import pyplot as plt, image\n",
    "import string\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Dict\n",
    "import cv2\n",
    "import matplotlib.patches as patches\n",
    "import json\n",
    "from imagehash import phash\n",
    "import math\n",
    "%matplotlib inline \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68b752f-cdb3-466b-a806-805fbfc808a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "safechars = string.ascii_lowercase + string.ascii_uppercase + string.digits + '.-_'\n",
    "def to_safechars(input: str) -> str:\n",
    "    return ''.join([c for c in input if c in safechars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94158028-9dba-48c9-ba28-789d7ff6335d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9c66ae-df79-4f0f-a7aa-a5dbdcee28b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stash_ai.model import Performer\n",
    "from sqlalchemy import select\n",
    "stmt = select(Performer)\n",
    "with get_session() as session:\n",
    "    results= session.execute(stmt)\n",
    "    for o in results:\n",
    "        print(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a87700-873f-4a31-800a-6ba49d905db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stash_ai.model import Performer\n",
    "\n",
    "with get_session() as session:\n",
    "    performer= session.get(Performer, 1)\n",
    "    print(performer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bf13e6-2ec5-4979-8f51-b3493a28cfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_id= 1659\n",
    "scene_id= 1\n",
    "#scene_id= 241\n",
    "scene= None\n",
    "html= None\n",
    "total_frames= 0\n",
    "frames_per_seconds= 0\n",
    "duration= 0\n",
    "url= None\n",
    "performers_images= []\n",
    "html= \"\"\n",
    "scene= config.stash_interface.find_scene(scene_id)\n",
    "if scene:\n",
    "    url= scene.get(\"paths\",{}).get(\"stream\")\n",
    "    html= f\"\"\"\n",
    "    <h1>{scene.get('title')}</h1>\n",
    "    <p>{scene.get('details')}</p>\n",
    "    \"\"\"\n",
    "    for file_info in scene.get('files'):\n",
    "        frames_per_seconds= file_info.get('frame_rate', 0)\n",
    "        duration= file_info.get('duration', 0)\n",
    "        total_frames= math.ceil(file_info.get('duration', 0) * file_info.get('frame_rate', 0))\n",
    "        html+=f\"\"\"\n",
    "        <p>Filename {file_info.get('basename')} duration: {file_info.get('duration')} seconds. Frame per seconds : {file_info.get('frame_rate')}. Total frames : {total_frames}</p>\n",
    "        \"\"\"\n",
    "    for performer_data in scene.get('performers', []):\n",
    "        performer_id= performer_data.get('id')\n",
    "        logger.info(f\"fetch_scene_from_stash Performer {performer_id}\")\n",
    "        if performer_id:\n",
    "            with get_session() as session:\n",
    "                performer= load_performer(performer_id, session)\n",
    "                performer_img= None\n",
    "                \n",
    "                if performer is not None:\n",
    "                    performer_img= get_performer_stash_image(performer)\n",
    "                    performer_text= f\"{performer.name} [{performer.id}]\"\n",
    "                else:\n",
    "                    performer_text= f\"Not found [{performer_id}]\"\n",
    "                \n",
    "                if performer_img is None:\n",
    "                    performer_img= get_unknown_performer_image()\n",
    "                \n",
    "                performers_images.append((performer_img, performer_text))\n",
    "                session.commit()\n",
    "else:\n",
    "    print(\"Unable to load scene\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7d9b60-c6df-4de2-9700-f0ea91c8353b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(json.dumps(scene, indent=2))\n",
    "display.display(display.JSON(scene))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390392e8-c73b-490b-a979-fa1c9c257ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"scene_id {scene_id}, url {url}, duration {duration}, total_frames {total_frames}, frames_per_seconds {frames_per_seconds} performers_images len:{len(performers_images)}\")\n",
    "display.display(display.HTML(html))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56630470-8474-489b-b40d-d8514d98affd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import gradio as gr\n",
    "import imagehash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07985611-1715-4452-af21-272d01e971cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_distance(left_hash, right_hash):\n",
    "    \"\"\"Compute the hamming distance between two hashes\"\"\"\n",
    "    if len(left_hash) != len(right_hash):\n",
    "        raise ValueError('Hamming distance requires two strings of equal length')\n",
    "\n",
    "    return sum(map(lambda x: 0 if x[0] == x[1] else 1, zip(left_hash, right_hash)))\n",
    "\n",
    "\n",
    "def hashes_are_similar(left_hash, right_hash, tolerance=6):\n",
    "    \"\"\"\n",
    "    Return True if the hamming distance between\n",
    "    the image hashes are less than the given tolerance.\n",
    "    \"\"\"\n",
    "    return (left_hash - right_hash) <= tolerance\n",
    "    return hash_distance(left_hash, right_hash) <= tolerance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83db0550-98a9-463d-9706-05d83817291b",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_url= url\n",
    "video_duration= duration\n",
    "fps= frames_per_seconds\n",
    "extract_n_images_per_seconds= 0.2\n",
    "number_of_samples=10\n",
    "progress= None\n",
    "#def extract_video_images(video_url, video_duration: float, fps: float, extract_n_images_per_seconds: float, number_of_samples, progress= None):\n",
    "logger.info(f\"extract_images URL: {video_url} Img per second : {extract_n_images_per_seconds} FPS: {fps} \")\n",
    "images= {}\n",
    "nb_frames= math.floor(video_duration*fps)\n",
    "\n",
    "if progress is not None:\n",
    "    progress(0, desc=\"Extracting...\", total=nb_frames, unit=\"frame\")\n",
    "else:\n",
    "    p= tqdm(desc=\"Extracting...\", total=nb_frames, unit=\"frame\")\n",
    "    progress= p.update\n",
    "\n",
    "extract_directory= config.data_dir.joinpath('scene_extraction').joinpath(f\"extracted_images_{scene_id}\")\n",
    "extract_directory_512= config.data_dir.joinpath('scene_extraction').joinpath(f\"extracted_images_{scene_id}_512\")\n",
    "logger.info(f\"extract_images: {extract_directory.resolve()}\")\n",
    "\n",
    "for d in [extract_directory , extract_directory_512]:\n",
    "    if d.exists():\n",
    "        shutil.rmtree(d)\n",
    "    d.mkdir(parents=True)\n",
    "\n",
    "if video_url is None:\n",
    "    gr.Warning(\"Url is empty, could not extract.\")\n",
    "else:\n",
    "    nb_extracted= 0\n",
    "    frame= 0\n",
    "    try:\n",
    "        logger.info(f\"extract_images Open VideoCapture {video_url}\")\n",
    "        cap= cv2.VideoCapture(video_url)\n",
    "        success= True\n",
    "        while success:\n",
    "            success, image= cap.read()\n",
    "            if success:\n",
    "                #h= imagehash.dhash(Image.fromarray(image), hash_size=8)\n",
    "                pImg= Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "                h= imagehash.phash(pImg)\n",
    "                frame+= 1\n",
    "                if frame % 500 == 0:\n",
    "                    logger.debug(f\"Image {nb_extracted} frame {frame} of {nb_frames}\")\n",
    "                if progress is not None:\n",
    "                    #progress(frame/nb_frames)\n",
    "                    progress()\n",
    "                # if frame == 500:\n",
    "                #     break\n",
    "                for oh in images.keys():\n",
    "                    if hashes_are_similar(h, oh, 20):\n",
    "                        break\n",
    "                else:\n",
    "                    #logger.info(f\"frame {frame} hash {h} {type(h)}\")\n",
    "                    #image_path= extract_directory.joinpath(f\"{nb_extracted:010}.jpg\")\n",
    "                    image_path= extract_directory.joinpath(f\"{h}.jpg\")\n",
    "                    if nb_extracted % 10 == 0:\n",
    "                        logger.info(f\"{image_path.name} : {pImg.size}\")\n",
    "                    pImg.save(image_path)\n",
    "                    pImg.thumbnail((512,512))\n",
    "                    image_path= extract_directory_512.joinpath(f\"{h}.jpg\")\n",
    "                    if nb_extracted % 10 == 0:\n",
    "                        logger.debug(f\"{image_path.name} thumbnail: {pImg.size}\")\n",
    "                    pImg.save(image_path)\n",
    "                    \n",
    "                    nb_extracted+= 1\n",
    "                    images[h]= image_path\n",
    "                    \n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"extract_images Error extraction {video_url} : {e!s}\")\n",
    "        logger.exception(e)\n",
    "    logger.info(f\"extract_images Extracted {nb_extracted} / {frame}\")\n",
    "print(f\"{len(images)} images\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
